<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ethics on Digitaliziran</title><link>https://cbuctok.github.io/digitaliziran.si/categories/ethics/</link><description>Recent content in Ethics on Digitaliziran</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 24 Sep 2025 14:32:38 +0000</lastBuildDate><atom:link href="https://cbuctok.github.io/digitaliziran.si/categories/ethics/index.xml" rel="self" type="application/rss+xml"/><item><title>California Fines Lawyer $10,000 for ChatGPT Fabrications: Is Your Legal Team Ready for AI Accountability?</title><link>https://cbuctok.github.io/digitaliziran.si/2025/09/24/california-fines-lawyer-10000-for-chatgpt-fabrications-is-your-legal-team-ready-for-ai-accountability/</link><pubDate>Wed, 24 Sep 2025 14:32:38 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/09/24/california-fines-lawyer-10000-for-chatgpt-fabrications-is-your-legal-team-ready-for-ai-accountability/</guid><description>&lt;p&gt;Have you ever wondered what happens when &lt;a href="https://en.wikipedia.org/wiki/Artificial_intelligence"&gt;artificial intelligence&lt;/a&gt; meets the courtroom? California just provided a stark answer, issuing a &lt;strong&gt;$10,000 fine&lt;/strong&gt; to a lawyer who submitted a court appeal filled with fabricated quotes generated by &lt;a href="https://openai.com/chatgpt"&gt;ChatGPT&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="the-wake-up-call-your-legal-department-needs"&gt;The Wake-Up Call Your Legal Department Needs&lt;/h2&gt;
&lt;p&gt;This case represents the first such sanction at the state appellate level, but it&amp;rsquo;s not the groundbreaking regulatory milestone it might initially appear. Federal courts have been issuing sanctions for AI-generated fake citations since 2023, most notably in the well-documented &lt;a href="https://en.wikipedia.org/wiki/Mata_v._Avianca,_Inc."&gt;Mata v. Avianca case&lt;/a&gt; in New York federal court where lawyers were sanctioned for similar ChatGPT fabrications.&lt;/p&gt;</description></item><item><title>Are You Ready for Your Robot Teammate? The Rise of Human-Robot Collaboration in the Modern Workplace</title><link>https://cbuctok.github.io/digitaliziran.si/2025/09/02/are-you-ready-for-your-robot-teammate-the-rise-of-human-robot-collaboration-in-the-modern-workplace/</link><pubDate>Tue, 02 Sep 2025 18:03:00 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/09/02/are-you-ready-for-your-robot-teammate-the-rise-of-human-robot-collaboration-in-the-modern-workplace/</guid><description>&lt;p&gt;Picture this: You walk into your office tomorrow and meet your new colleague - a &lt;a href="https://www.epicor.com/en-us/blog/technology-and-data/the-role-of-cobots-in-enhancing-workplace-safety/"&gt;collaborative robot&lt;/a&gt;, or &amp;ldquo;cobot,&amp;rdquo; designed to work alongside you. This isn&amp;rsquo;t science fiction; it&amp;rsquo;s the reality of &lt;a href="https://www.sciencedirect.com/science/article/pii/S1877050924003223"&gt;Industry 5.0&lt;/a&gt;, where human-robot collaboration is transforming workplaces across manufacturing, healthcare, and service industries.&lt;/p&gt;
&lt;h2 id="the-shift-from-automation-to-collaboration"&gt;The Shift from Automation to Collaboration&lt;/h2&gt;
&lt;p&gt;Unlike traditional &lt;a href="https://www.osha.gov/robotics"&gt;industrial robots&lt;/a&gt; confined behind safety barriers, &lt;strong&gt;collaborative robots (cobots)&lt;/strong&gt; are engineered to work in shared spaces with humans. According to recent research from &lt;a href="https://asmedigitalcollection.asme.org/computingengineering/article/25/5/050301/1213609/Special-Issue-Human-Robot-Collaboration-in"&gt;ASME Digital Collection&lt;/a&gt;, the proper design of individual and joint tasks for humans and cobots can maximize collaborative potential, creating more efficient and adaptable work environments.&lt;/p&gt;</description></item><item><title>Sweden's PM ChatGPT Scandal Exposes Critical AI Governance Gap: Why ISO 42001 Is No Longer Optional</title><link>https://cbuctok.github.io/digitaliziran.si/2025/08/08/swedens-pm-chatgpt-scandal-exposes-critical-ai-governance-gap-why-iso-42001-is-no-longer-optional/</link><pubDate>Fri, 08 Aug 2025 18:41:06 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/08/08/swedens-pm-chatgpt-scandal-exposes-critical-ai-governance-gap-why-iso-42001-is-no-longer-optional/</guid><description>&lt;p&gt;When Sweden&amp;rsquo;s Prime Minister Ulf Kristersson &lt;a href="https://www.theguardian.com/technology/2025/aug/05/chat-gpt-swedish-pm-ulf-kristersson-under-fire-for-using-ai-in-role"&gt;admitted using ChatGPT&lt;/a&gt; to get a &amp;ldquo;second opinion&amp;rdquo; on policy matters in August 2025, the backlash was swift. &amp;ldquo;We didn&amp;rsquo;t vote for ChatGPT,&amp;rdquo; critics declared. While this incident has sparked important debates about transparency in government, it also highlights broader questions about how organizations should manage &lt;a href="https://cloud.google.com/learn/what-is-artificial-intelligence"&gt;artificial intelligence (AI)&lt;/a&gt; tools responsibly.&lt;/p&gt;
&lt;h2 id="understanding-the-swedish-controversy"&gt;Understanding the Swedish Controversy&lt;/h2&gt;
&lt;p&gt;To be clear, Prime Minister Kristersson clarified that he uses &lt;a href="https://www.techtarget.com/whatis/definition/ChatGPT"&gt;ChatGPT&lt;/a&gt; - an AI-powered chatbot that can generate human-like text responses - for consultation rather than actual governmental decision-making. This distinction is important: seeking a &amp;ldquo;second opinion&amp;rdquo; from AI tools is different from delegating decision-making authority to them.&lt;/p&gt;</description></item><item><title>Is Your Business Ready for Europe's AI Language Revolution? Microsoft's Bold Move Could Leave You Behind</title><link>https://cbuctok.github.io/digitaliziran.si/2025/07/22/is-your-business-ready-for-europes-ai-language-revolution-microsofts-bold-move-could-leave-you-behind/</link><pubDate>Tue, 22 Jul 2025 08:16:37 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/07/22/is-your-business-ready-for-europes-ai-language-revolution-microsofts-bold-move-could-leave-you-behind/</guid><description>&lt;p&gt;When was the last time you considered whether your AI tools truly understand your customers&amp;rsquo; native languages? If you&amp;rsquo;re operating in Europe&amp;rsquo;s diverse linguistic landscape, Microsoft&amp;rsquo;s latest announcement should make you pause and reassess your digital strategy.&lt;/p&gt;
&lt;h2 id="the-wake-up-call-europe-needed"&gt;The Wake-Up Call Europe Needed&lt;/h2&gt;
&lt;p&gt;Microsoft recently launched two initiatives that could reshape how AI serves Europe&amp;rsquo;s 200+ languages, though the impact may be more incremental than revolutionary. The tech giant&amp;rsquo;s &lt;a href="https://blogs.microsoft.com/on-the-issues/2025/07/20/eudigitalunlock/"&gt;European Digital Unlock program&lt;/a&gt; isn&amp;rsquo;t just another corporate initiative - it&amp;rsquo;s a direct response to a critical gap that&amp;rsquo;s been undermining European businesses for years.&lt;/p&gt;</description></item><item><title>EU's New AI Code of Practice: Are You Ready for August 2025's Compliance Reality Check?</title><link>https://cbuctok.github.io/digitaliziran.si/2025/07/22/eus-new-ai-code-of-practice-are-you-ready-for-august-2025s-compliance-reality-check/</link><pubDate>Tue, 22 Jul 2025 08:00:35 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/07/22/eus-new-ai-code-of-practice-are-you-ready-for-august-2025s-compliance-reality-check/</guid><description>&lt;p&gt;Is your organization prepared for the seismic shift coming to AI governance this August? The European Commission has just published its voluntary &lt;a href="https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai"&gt;General-Purpose AI Code of Practice (GPAI-CoP)&lt;/a&gt;, and while &amp;ldquo;voluntary&amp;rdquo; might sound reassuring, the practical reality is far more complex.&lt;/p&gt;
&lt;h2 id="the-august-2025-deadline-that-changes-everything"&gt;The August 2025 Deadline That Changes Everything&lt;/h2&gt;
&lt;p&gt;When the &lt;a href="https://www.dlapiper.com/en-us/insights/publications/2025/07/european-union-published-code-of-practice"&gt;EU AI Act takes full effect on August 2, 2025&lt;/a&gt;, your AI systems will face unprecedented scrutiny. The newly published code provides a roadmap for compliance, but it also reveals the technical challenges ahead - particularly around &lt;strong&gt;fairness&lt;/strong&gt;, which experts describe as &lt;a href="https://www.lewissilkin.com/insights/2025/07/18/european-commission-consults-on-digital-fairness-act-102ku4t"&gt;&amp;ldquo;an important and technically challenging aspect of AI.&amp;rdquo;&lt;/a&gt;&lt;/p&gt;</description></item><item><title>NYT v. OpenAI: Why Your Data Privacy May Be at Risk Even After You Hit Delete</title><link>https://cbuctok.github.io/digitaliziran.si/2025/06/08/nyt-v-openai-why-your-data-privacy-may-be-at-risk-even-after-you-hit-delete/</link><pubDate>Sun, 08 Jun 2025 06:56:55 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/06/08/nyt-v-openai-why-your-data-privacy-may-be-at-risk-even-after-you-hit-delete/</guid><description>&lt;p&gt;Are you confident that your deleted conversations with AI chatbots are really gone? A &lt;strong&gt;landmark lawsuit&lt;/strong&gt; between &lt;a href="https://harvardlawreview.org/blog/2024/04/nyt-v-openai-the-timess-about-face/"&gt;The New York Times (NYT) and OpenAI&lt;/a&gt; reveals a troubling reality: “deleted” data might still be stored, analyzed, or exposed in ways you never intended or consented to.&lt;/p&gt;
&lt;h3 id="your-deleted-data-isnt-always-deleted"&gt;Your Deleted Data Isn&amp;rsquo;t Always Deleted&lt;/h3&gt;
&lt;p&gt;According to &lt;a href="https://www.theverge.com/news/681280/openai-storing-deleted-chats-nyt-lawsuit"&gt;The Verge&lt;/a&gt;, OpenAI has stored deleted conversations, despite users’ expectation of privacy. This practice is currently being challenged in court and has sparked debate around what “delete” really means in the context of &lt;strong&gt;AI chatbots&lt;/strong&gt; and cloud-based interactions.&lt;/p&gt;</description></item><item><title>Is Your Team Ready for AI? Why Education Must Come Before Implementation</title><link>https://cbuctok.github.io/digitaliziran.si/2025/06/02/is-your-team-ready-for-ai-why-education-must-come-before-implementation/</link><pubDate>Mon, 02 Jun 2025 08:35:28 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/06/02/is-your-team-ready-for-ai-why-education-must-come-before-implementation/</guid><description>&lt;p&gt;Picture this: your organization just invested in cutting-edge AI technology, but your team doesn&amp;rsquo;t understand how it works, when it might fail, or what legal obligations come with its use. Sound familiar? You&amp;rsquo;re not alone—and you&amp;rsquo;re potentially in violation of the &lt;a href="https://www.lexia.it/en/2025/05/30/ai-literacy-and-faqs/"&gt;European AI Act&lt;/a&gt;, which mandates AI literacy training as of February 2, 2025.&lt;/p&gt;
&lt;h2 id="the-knowledge-first-imperative"&gt;The Knowledge-First Imperative&lt;/h2&gt;
&lt;p&gt;The principle is simple yet revolutionary: &lt;strong&gt;knowledge is power, and it&amp;rsquo;s crucial for successful AI integration to have educated personnel first, not after integration&lt;/strong&gt;. This isn&amp;rsquo;t just good practice—it&amp;rsquo;s now a legal requirement under EU regulations.&lt;/p&gt;</description></item><item><title>White House Health Report Scandal Exposes the Dangers of Unvetted AI in Government</title><link>https://cbuctok.github.io/digitaliziran.si/2025/05/31/white-house-health-report-scandal-exposes-the-dangers-of-unvetted-ai-in-government/</link><pubDate>Sat, 31 May 2025 09:05:15 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/05/31/white-house-health-report-scandal-exposes-the-dangers-of-unvetted-ai-in-government/</guid><description>&lt;p&gt;Are you trusting AI tools to handle critical decisions in your organization? The Trump administration&amp;rsquo;s recent health report debacle should serve as a wake-up call for every executive relying on artificial intelligence without proper oversight.&lt;/p&gt;
&lt;h2 id="when-ai-goes-rogue-at-the-highest-levels"&gt;When AI Goes Rogue at the Highest Levels&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://www.washingtonpost.com/health/2025/05/29/maha-rfk-jr-ai-garble/"&gt;White House&amp;rsquo;s &amp;ldquo;Make America Healthy Again&amp;rdquo; (MAHA) report&lt;/a&gt; contained fabricated citations and potentially AI-generated content that experts say bears the hallmarks of unvetted artificial intelligence use. &lt;a href="https://www.nytimes.com/2025/05/29/well/maha-report-citations.html"&gt;Multiple news outlets&lt;/a&gt; have confirmed that the report included non-existent studies and garbled scientific references—exactly the kind of errors we see when AI tools operate without human verification.&lt;/p&gt;</description></item><item><title>AI Companion Chatbots Deemed Unsafe for Children, Raising Questions About Digital Boundaries</title><link>https://cbuctok.github.io/digitaliziran.si/2025/05/01/ai-companion-chatbots-deemed-unsafe-for-children-raising-questions-about-digital-boundaries/</link><pubDate>Thu, 01 May 2025 11:09:18 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/05/01/ai-companion-chatbots-deemed-unsafe-for-children-raising-questions-about-digital-boundaries/</guid><description>&lt;p&gt;A &lt;a href="https://www.cnn.com/2025/04/30/tech/ai-companion-chatbots-unsafe-for-kids-report"&gt;new report&lt;/a&gt; has sounded the alarm on AI companion chatbots, declaring them unsafe for children and teens under 18. The &lt;a href="https://sd18.senate.ca.gov/news/senator-padilla-introduces-legislation-protect-children-predatory-chatbot-practices"&gt;safety assessment&lt;/a&gt;, released this week, calls for stringent measures—potentially including legal restrictions—to protect young users from the psychological and developmental risks these increasingly popular AI systems pose.&lt;/p&gt;
&lt;p&gt;These AI companions, designed to simulate human-like conversations and relationships, have gained millions of users worldwide. However, researchers found these platforms can create unhealthy emotional dependencies, expose children to inappropriate content, and potentially undermine critical social development that occurs through human interaction.&lt;/p&gt;</description></item><item><title>Navigating the AI Era - Fostering Critical Thinking in Human-AI Interactions</title><link>https://cbuctok.github.io/digitaliziran.si/2025/04/18/navigating-the-ai-era-fostering-critical-thinking-in-human-ai-interactions/</link><pubDate>Fri, 18 Apr 2025 15:30:00 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/04/18/navigating-the-ai-era-fostering-critical-thinking-in-human-ai-interactions/</guid><description>&lt;p&gt;Understanding the &amp;ldquo;Ironies of Generative AI&amp;rdquo; and its impact on critical thinking is the first step towards mitigating the potential negative consequences. Both the &lt;a href="https://arxiv.org/pdf/2402.11364"&gt;2024&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf"&gt;2025&lt;/a&gt; studies offer valuable insights and action points for designing and utilizing GenAI tools in a way that supports and enhances human capabilities.&lt;/p&gt;
&lt;p&gt;The 2024 study emphasizes the importance of &lt;strong&gt;Human Factors principles&lt;/strong&gt; in GenAI system design, suggesting approaches like &lt;strong&gt;continuous feedback, system personalization, ecological interface design, task stabilization, and clear task allocation&lt;/strong&gt;. These principles aim to increase user agency, improve situational awareness, and enhance flexibility in how users interact with AI, ultimately reducing cognitive load and workflow disruptions.&lt;/p&gt;</description></item><item><title>The Cognitive Impact - How GenAI Reshapes Critical Thinking</title><link>https://cbuctok.github.io/digitaliziran.si/2025/04/11/the-cognitive-impact-how-genai-reshapes-critical-thinking/</link><pubDate>Fri, 11 Apr 2025 15:00:00 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/04/11/the-cognitive-impact-how-genai-reshapes-critical-thinking/</guid><description>&lt;p&gt;Building on the understanding of the &amp;ldquo;Ironies of GenAI,&amp;rdquo; recent research went deeper into the specific cognitive impacts of these powerful tools, particularly on &lt;strong&gt;critical thinking&lt;/strong&gt;. A 2025 study, &amp;ldquo;&lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf"&gt;The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers&lt;/a&gt;,&amp;rdquo; provides crucial insights into this domain.&lt;/p&gt;
&lt;p&gt;The study found that while GenAI can enhance efficiency, it also introduces significant shifts in how knowledge workers engage in critical thinking. One key finding revolves around &lt;strong&gt;&amp;ldquo;Confidence Effects&amp;rdquo;&lt;/strong&gt;: higher confidence in GenAI&amp;rsquo;s ability to perform a task is associated with less critical thinking, even though users might perceive it as less effortful. Conversely, higher self-confidence in one&amp;rsquo;s own ability to do the task is linked to more critical thinking, often accompanied by a perception of greater effort. This suggests a risk of &lt;strong&gt;over-reliance&lt;/strong&gt; on AI, where users may accept outputs without sufficient critical evaluation, potentially leading to errors and a decline in independent problem-solving skills.&lt;/p&gt;</description></item><item><title>The Generative Leap - Echoes of Automation in the Age of AI</title><link>https://cbuctok.github.io/digitaliziran.si/2025/04/04/the-generative-leap-echoes-of-automation-in-the-age-of-ai/</link><pubDate>Fri, 04 Apr 2025 15:00:00 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/04/04/the-generative-leap-echoes-of-automation-in-the-age-of-ai/</guid><description>&lt;p&gt;Fast forward to the era of &lt;strong&gt;Generative Artificial Intelligence (GenAI)&lt;/strong&gt;, and we see a striking resemblance to the &amp;ldquo;Ironies of Automation.&amp;rdquo; A 2024 study, &amp;ldquo;&lt;a href="https://arxiv.org/pdf/2402.11364"&gt;Ironies of Generative AI: Understanding and mitigating productivity loss in human-AI interactions&lt;/a&gt;,&amp;rdquo; explicitly draws on this decades-long Human Factors research to understand the challenges emerging with GenAI systems. While GenAI promises to boost productivity in various knowledge-intensive domains like programming and writing, numerous studies reveal users working ineffectively with these systems and experiencing productivity losses.&lt;/p&gt;</description></item><item><title>The Automation Paradox - When Machines Make Humans More Crucial</title><link>https://cbuctok.github.io/digitaliziran.si/2025/03/28/the-automation-paradox-when-machines-make-humans-more-crucial/</link><pubDate>Fri, 28 Mar 2025 15:23:55 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/03/28/the-automation-paradox-when-machines-make-humans-more-crucial/</guid><description>&lt;p&gt;For decades, the promise of automation has been clear: machines taking over tedious, error-prone tasks, freeing up humans for more strategic and creative endeavors. Yet, as early as 1983, Lisanne Bainbridge highlighted a fascinating paradox in her seminal work, &lt;strong&gt;&amp;quot;&lt;a href="https://web.archive.org/web/20200717054958if_/https://www.ise.ncsu.edu/wp-content/uploads/2017/02/Bainbridge_1983_Automatica.pdf"&gt;Ironies of Automation&lt;/a&gt;&amp;quot;&lt;/strong&gt;. She observed that the more advanced an automated system becomes, the more critical the role of the human operator often becomes. This isn&amp;rsquo;t the straightforward efficiency gain one might expect; instead, it introduces a new set of challenges.&lt;/p&gt;</description></item><item><title>Ethics Principles Reference Table</title><link>https://cbuctok.github.io/digitaliziran.si/2025/03/22/ethics-principles-reference-table/</link><pubDate>Sat, 22 Mar 2025 09:10:43 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/03/22/ethics-principles-reference-table/</guid><description>&lt;p&gt;This table outlines fundamental ethical principles applicable across various domains, including healthcare, law, and business. Each principle is defined, illustrated with a practical example, and justified by its importance in fostering ethical conduct. The principles encompass respect for autonomy, non-maleficence, beneficence, justice, veracity, fidelity, and self-respect, collectively forming a framework for moral decision-making and interpersonal interactions. This concise overview serves as a foundational guide to understanding and applying these core ethical values in professional and personal contexts.&lt;/p&gt;</description></item></channel></rss>