<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MCP on Digitaliziran</title><link>https://cbuctok.github.io/digitaliziran.si/tags/mcp/</link><description>Recent content in MCP on Digitaliziran</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 14 Apr 2025 19:40:38 +0000</lastBuildDate><atom:link href="https://cbuctok.github.io/digitaliziran.si/tags/mcp/index.xml" rel="self" type="application/rss+xml"/><item><title>Model Context Protocol: A Security Threat Masquerading as Innovation</title><link>https://cbuctok.github.io/digitaliziran.si/2025/04/14/model-context-protocol-a-security-threat-masquerading-as-innovation/</link><pubDate>Mon, 14 Apr 2025 19:40:38 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/04/14/model-context-protocol-a-security-threat-masquerading-as-innovation/</guid><description>&lt;p&gt;The tech world is abuzz with discussions about the Model Context Protocol (MCP), but security experts are raising red flags that should concern every organization considering its implementation. Far from being the revolutionary protocol its proponents claim, MCP may represent a significant security vulnerability that could compromise sensitive data and systems.&lt;/p&gt;
&lt;p&gt;MCP purports to facilitate communication between language models and external tools, creating a standardized way for AI systems to access data sources and execute functions. However, as detailed in a recent analysis, this so-called &amp;ldquo;protocol&amp;rdquo; is more accurately described as a scheme that lacks fundamental security safeguards.&lt;/p&gt;</description></item><item><title>Thinking About Deploying AI Agents? Read This First.</title><link>https://cbuctok.github.io/digitaliziran.si/2025/04/02/thinking-about-deploying-ai-agents-read-this-first/</link><pubDate>Wed, 02 Apr 2025 08:42:04 +0000</pubDate><guid>https://cbuctok.github.io/digitaliziran.si/2025/04/02/thinking-about-deploying-ai-agents-read-this-first/</guid><description>&lt;p&gt;So, your team is buzzing about the latest AI agents â€“ those clever systems that can automate complex tasks, maybe even act as personal assistants? They sound fantastic, promising leaps in productivity. But before you dive headfirst into deployment, let&amp;rsquo;s talk about a critical risk NIST is highlighting: &lt;strong&gt;agent hijacking&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What&amp;rsquo;s Agent Hijacking?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Imagine an attacker slipping malicious instructions into the data your shiny new AI agent uses. Suddenly, instead of helping, it&amp;rsquo;s performing harmful actions you never intended. That&amp;rsquo;s agent hijacking, a sneaky form of indirect prompt injection, and it&amp;rsquo;s a real threat.&lt;/p&gt;</description></item></channel></rss>